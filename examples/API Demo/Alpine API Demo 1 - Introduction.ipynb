{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Alpine API 1 - Running workflows and examing the results.  \n",
    "## Using the Alpine API Python wrapper to:\n",
    "1. Initialize a session\n",
    "1. Run a workflow\n",
    "1. Download and analyze the results\n",
    "\n",
    "### Resources:\n",
    "1.  [API documentation](https://alpine.atlassian.net/wiki/display/V5/Alpine+API)\n",
    "2.  [API Demo](https://alpine.atlassian.net/wiki/display/V5/Alpine+API+Demo)\n",
    "3.  [Anaconda Python](https://store.continuum.io/cshop/anaconda/) - All-in-one Python distribution.\n",
    "4.  [Jupyter](http://jupyter.org/) - aka iPython notebook.  Included with Anaconda Python.\n",
    "5.  [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html) - Source of data used in this demo.\n",
    "\n",
    "### To access list of API functions, add /api to your alpine host:port URL.  Example: 10.0.0.216:8080/api\n",
    "(Add new documentation)\n",
    "### Setup:\n",
    "\n",
    "1.  Create a new workspace called \"API Demos\" on your Alpine installation.\n",
    "1.  Upload the included workflow API_Demo_1.afm into the new workspace.\n",
    "1.  Upload the included data set, (magic04.csv), to your data source.\n",
    "1.  Open the workflow and configure the data set to point to the location of your dataset in HDFS.  The default setting uses Spark to fit the logistic regression model.  You can turn off Spark in the Logistic Regression operator dialogue menu.\n",
    "1.  Run the workflow through the Alpine UI to make sure that everything is configured correctly.\n",
    "\n",
    "### Let's set some values that we'll be using in the demo. Find the url of the open work flow. You can read the host, port and workflow id from the url. For example, if the url is  http://10.10.0.204:8080/#work_flows/320:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "host = \"10.10.0.204\"\n",
    "port = \"8080\"\n",
    "workflow_id = \"322\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You'll also need your Alpine username and password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"demoadmin\"\n",
    "password = \"password\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some setup by importing some libraries and starting an API session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import api as AlpineAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-24 15:56:32,087 requests.packages.urllib3.connectionpool connectionpool[214] INFO: Starting new HTTP connection (1): 10.10.0.204\n"
     ]
    }
   ],
   "source": [
    "session = AlpineAPI.Alpine(host, port, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some of the API calls are going to be used many times in this demo.  To keep organized, and to reduce repeated code, I'll wrap these API calls in a function.  Here's one for logging in to Alpine.  First, we build the correct URL and body information to authenticate.  Getting a JSON object in response indicates a succesful login.  We will need to use the session_id later, so I'll return it from `login()` and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_login_status().get(\"response\").get(\"user\").get(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's the *API Demo 1* workflow.  It's a basic classification workflow, using a test/train split to verify that our logistic regression model generalizes well to the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='Images/Demo1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the workflow. We can use the .workfile.run_workflow() function. It wil construct the proper url for you, create a post request. A succesful post will return a process id unique to this run. We can use the id to query the workflow or download results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab8f7dc6-c8e1-499e-8a15-f8290b206ca8\n"
     ]
    }
   ],
   "source": [
    "process_id = session.workfile.run_workflow(workflow_id)\n",
    "print(process_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflows can take a while to complete.  We can poll the status of the workflow using .workfile.query_workflow_status().  You can run this cell several times to see how the status changes as the workflow progresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORKING'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.workfile.query_workflow_status(process_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could continue to run the previous cell over and over to test if the workflow is complete, but we also have a convenience method to do this automatically. By default, it queries the workflow status every 10 seconds.\n",
    "\n",
    "### Run the next cell while the workflow is still in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow in progress for ~20 seconds."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FINISHED'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session.workfile.wait_for_workflow_to_finish(process_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can download the result.  `workflow_result` contains all the information that appears in the bottom window of the Alpine workflow editor, along with some logs and metadata.   To access that information we can convert it from a JSON string to a nested dict/list python object.  This can potentially be quite large.  Generally, we won't want to print it to screen, but go ahead and do it once if you are curious.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "workflow_result = session.workfile.download_workflow_results(workflow_id, process_id)\n",
    "\n",
    "pprint(workflow_result, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The output  from each operator is stored in the list `result['outputs']`.  For instance, the name of the ith operator can be found at `result['outputs'][i]['out_title']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "operator_list = workflow_result['outputs']\n",
    "print(\"Number of operators in workflow = {}\".format(len(operator_list)))\n",
    "print(\"Name of the 3rd operator is '{}'\".format(operator_list[3]['out_title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are interested in knowing the prediction accuracy of our trained logistic regression model on the test set.  In the workflow, this is calculated in the *Confusion Matrix* operator.  We can iterate over this list to find the operator that has the matching name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def find_operator(name, oper_list):\n",
    "#     for oper in oper_list:\n",
    "#         if oper['out_title'] == name:\n",
    "#             return oper\n",
    "#     return []\n",
    "\n",
    "matching_name = 'Confusion Matrix'\n",
    "output_operator = session.workfile.find_operator(matching_name, operator_list)\n",
    "pprint(output_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each operator has a different data output format, but for a *Confusion Matrix* we can find the prediction accuracy on the test set like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = output_operator['visualData'][1]['visualData']['heatMapTable']['accuracy']\n",
    "print(\"Accuracy = {0:.1f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
